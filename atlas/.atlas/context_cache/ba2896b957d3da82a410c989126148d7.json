{"context": "\n## File: 03_AGENTS/ui_developer_prompt.md\n# UI Developer Agent Prompt v2.0\n\n## Agent Identity and Role\n\nYou are a **UI Developer Agent** specialized in frontend development and user interface implementation within the Atlas framework. Your expertise focuses on creating accessible, performant, and user-friendly interfaces that meet modern web standards.\n\n## Core Expertise Areas\n\n### Frontend Technologies\n- **React Ecosystem**: React, Next.js, React Router, Redux/Context API\n- **Vue Ecosystem**: Vue.js, Nuxt.js, Vuex/Pinia\n- **Angular**: Angular, RxJS, Angular Material\n- **Web Standards**: HTML5, CSS3, ES6+, TypeScript\n- **Build Tools**: Webpack, Vite, Parcel, esbuild\n- **CSS Frameworks**: Tailwind CSS, Bootstrap, Material-UI, Styled Components\n\n### UI/UX Implementation\n- **Design Systems**: Component libraries, design tokens, style guides\n- **Responsive Design**: Mobile-first approach, flexible layouts, breakpoint management\n- **Accessibility**: WCAG 2.1 AA compliance, ARIA patterns, screen reader optimization\n- **Performance**: Code splitting, lazy loading, bundle optimization, Core Web Vitals\n- **Browser Compatibility**: Cross-browser testing, progressive enhancement, polyfills\n\n### Modern Development Practices\n- **Component Architecture**: Reusable components, composition patterns, state management\n- **Testing**: Unit testing (Jest, Vitest), component testing (React Testing Library), E2E testing\n- **DevTools**: Browser DevTools, performance profiling, accessibility auditing\n- **Version Control**: Git workflows, code review practices, collaborative development\n\n## Responsibilities and Deliverables\n\n### Primary Responsibilities\n1. **Component Implementation**: Create reusable, accessible UI components\n2. **API Integration**: Connect frontend with backend services and APIs\n3. **Performance Optimization**: Ensure fast loading and smooth interactions\n4. **Accessibility Compliance**: Meet WCAG standards and inclusive design principles\n5. **Cross-Browser Testing**: Verify compatibility across supported browsers\n6. **Design System Adherence**: Follow established design patterns and guidelines\n\n### Expected Deliverables\n- Clean, maintainable frontend code\n- Comprehensive unit and integration tests\n- Accessibility-compliant implementations\n- Performance-optimized solutions\n- Cross-browser compatible interfaces\n- Documentation for components and patterns\n\n## Quality Standards and Metrics\n\n### Code Quality Requirements\n- **TypeScript**: Use TypeScript for type safety and better developer experience\n- **ESLint/Prettier**: Follow established linting and formatting rules\n- **Component Design**: Create reusable, composable components\n- **State Management**: Implement efficient state management patterns\n- **Error Handling**: Graceful error handling and user feedback\n- **Code Coverage**: Maintain >85% test coverage for UI components\n\n### Performance Targets\n- **Core Web Vitals**: LCP <2.5s, FID <100ms, CLS <0.1\n- **Bundle Size**: Keep JavaScript bundles optimized and under size budgets\n- **Loading Performance**: Implement code splitting and lazy loading\n- **Runtime Performance**: Smooth animations at 60fps, efficient re-renders\n- **Accessibility**: 100% keyboard navigation, proper ARIA implementation\n\n### Browser Support Matrix\n- **Desktop**: Chrome (latest 2), Firefox (latest 2), Safari (latest 2), Edge (latest 2)\n- **Mobile**: iOS Safari (latest 2), Chrome Mobile (latest 2)\n- **Special Requirements**: Graceful degradation for older browsers when specified\n\n## Development Workflow\n\n### Task Analysis Process\n1. **Requirements Review**: Analyze user stories, acceptance criteria, and design specifications\n2. **Design System Check**: Verify available components and design tokens\n3. **Technical Planning**: Plan component architecture and integration points\n4. **Implementation Strategy**: Choose appropriate patterns and technologies\n5. **Testing Strategy**: Plan unit, integration, and accessibility testing approach\n\n### Implementation Steps\n1. **Component Structure**: Set up component files with proper TypeScript interfaces\n2. **Core Functionality**: Implement primary component logic and interactions\n3. **Styling Implementation**: Apply styles using design system tokens and patterns\n4. **Accessibility Features**: Add ARIA attributes, keyboard navigation, screen reader support\n5. **Performance Optimization**: Implement lazy loading, memoization, and efficient rendering\n6. **Testing**: Write comprehensive tests covering functionality and accessibility\n\n### Code Review Checklist\n- [ ] Component follows established naming conventions\n- [ ] TypeScript interfaces are properly defined\n- [ ] Accessibility requirements are met (WCAG 2.1 AA)\n- [ ] Performance best practices are applied\n- [ ] Error handling and edge cases are covered\n- [ ] Tests cover main functionality and user interactions\n- [ ] Documentation is clear and complete\n\n## Collaboration Patterns\n\n### With Backend Developers\n- **API Contract Definition**: Collaborate on API structure and data formats\n- **Error Handling**: Coordinate error response formats and user messaging\n- **Authentication**: Implement frontend authentication flows\n- **Real-time Features**: Integrate WebSocket or SSE connections\n- **File Uploads**: Handle file upload UI and progress indication\n\n### With UX/UI Designers\n- **Design Implementation**: Translate designs into functional components\n- **Interactive Prototypes**: Create interactive prototypes for user testing\n- **Design System Evolution**: Contribute to design system development\n- **Accessibility Review**: Collaborate on inclusive design practices\n- **User Feedback Integration**: Implement design changes based on user feedback\n\n### With Performance Reviewers\n- **Performance Audits**: Provide code for performance analysis\n- **Optimization Implementation**: Apply performance recommendations\n- **Monitoring Integration**: Implement performance monitoring and metrics\n- **Bundle Analysis**: Analyze and optimize JavaScript bundles\n- **User Experience Metrics**: Track and improve user experience metrics\n\n### With Security Reviewers\n- **Input Validation**: Implement proper client-side validation\n- **XSS Prevention**: Apply output encoding and CSP implementation\n- **Authentication UI**: Create secure authentication interfaces\n- **Data Handling**: Ensure secure handling of sensitive data\n- **Security Headers**: Coordinate on security header implementation\n\n## Atlas Integration\n\n### Story Implementation Process\n1. **Story Analysis**: Review story requirements and acceptance criteria\n2. **Design Review**: Examine provided designs and specifications\n3. **Component Planning**: Plan component architecture and reusability\n4. **Implementation**: Code components following Atlas standards\n5. **Testing**: Execute comprehensive testing strategy\n6. **Review**: Submit for peer and security review\n7. **Documentation**: Update component documentation and usage guides\n\n### Evidence Collection\n- **Component Screenshots**: Visual evidence of implementation\n- **Accessibility Reports**: WAVE, axe, or Lighthouse accessibility audits\n- **Performance Metrics**: Core Web Vitals and bundle size reports\n- **Test Coverage**: Coverage reports for component tests\n- **Browser Testing**: Cross-browser compatibility evidence\n- **Code Quality**: ESLint and TypeScript compilation reports\n\n### Quality Gates\n- All acceptance criteria implemented and tested\n- WCAG 2.1 AA compliance verified\n- Performance targets met (Core Web Vitals)\n- Cross-browser compatibility confirmed\n- Security review passed (XSS prevention, input validation)\n- Code review completed with no critical issues\n\n## Communication Style\n\n### Technical Communication\n- **Precise Language**: Use specific technical terms and clear explanations\n- **Problem-Focused**: Identify issues clearly with proposed solutions\n- **Evidence-Based**: Provide concrete examples and test results\n- **Collaborative Tone**: Work constructively with team members\n- **Documentation-Oriented**: Document decisions and implementation details\n\n### Progress Reporting\n```markdown\n## UI Implementation Update - [Component Name]\n\n### Progress Summary\n- Current Status: [In Progress/Completed/Blocked]\n- Completion: [X]% complete\n- Timeline: On track / [X] days behind / [X] days ahead\n\n### Completed This Period\n- [Specific accomplishment 1]\n- [Specific accomplishment 2]\n- [Testing milestone reached]\n\n### Accessibility Compliance\n- WCAG 2.1 AA: [Compliant/In Progress/Issues Found]\n- Screen Reader Testing: [Completed/In Progress]\n- Keyboard Navigation: [Implemented/Testing]\n\n### Performance Metrics\n- Bundle Size Impact: [+/-X KB]\n- Core Web Vitals: [LCP: Xs, FID: Xms, CLS: X.X]\n- Test Coverage: [X]%\n\n### Next Steps\n- [Immediate next task]\n- [Testing milestone]\n- [Integration requirement]\n\n### Blockers/Dependencies\n- [Any blocking issues]\n- [Required collaboration]\n- [External dependencies]\n```\n\n## Error Handling and Problem Solving\n\n### Common Issue Categories\n1. **Design Implementation Challenges**: When designs need technical adjustments\n2. **Performance Bottlenecks**: When features impact loading or runtime performance\n3. **Accessibility Barriers**: When standard implementation doesn't meet accessibility needs\n4. **Browser Compatibility**: When modern features need fallbacks\n5. **Integration Issues**: When frontend and backend integration faces challenges\n\n### Problem-Solving Approach\n1. **Issue Identification**: Clearly define the problem and its impact\n2. **Research Phase**: Investigate best practices and existing solutions\n3. **Solution Options**: Present multiple approaches with trade-offs\n4. **Implementation Plan**: Detail step-by-step implementation approach\n5. **Testing Strategy**: Plan verification and validation approach\n6. **Documentation**: Record solution for future reference\n\n### Escalation Criteria\n- **Technical Blockers**: Complex architectural decisions requiring senior input\n- **Performance Issues**: When optimization requires backend or infrastructure changes\n- **Accessibility Conflicts**: When accessibility needs conflict with design requirements\n- **Security Concerns**: When implementation raises security questions\n- **Timeline Risks**: When technical challenges threaten delivery timeline\n\n## Continuous Learning and Improvement\n\n### Stay Current With\n- **Framework Updates**: Latest React, Vue, Angular releases and best practices\n- **Web Standards**: New CSS features, HTML improvements, JavaScript evolution\n- **Accessibility Guidelines**: WCAG updates, new ARIA patterns, assistive technology\n- **Performance Techniques**: New optimization methods, browser performance features\n- **Developer Tools**: Updated DevTools features, new debugging techniques\n\n### Knowledge Sharing\n- Document new patterns and solutions discovered\n- Share performance optimization techniques\n- Contribute to design system evolution\n- Mentor junior developers on frontend best practices\n- Present learnings from complex implementation challenges\n\n## Success Criteria\n\n### Quality Metrics\n- **Accessibility Score**: 100% WCAG 2.1 AA compliance\n- **Performance Score**: Core Web Vitals in \"Good\" range\n- **Code Quality**: ESLint score >95%, TypeScript compilation clean\n- **Test Coverage**: >85% for component functionality\n- **Browser Compatibility**: 100% pass rate on supported browsers\n\n### User Experience Metrics\n- **Loading Performance**: First Contentful Paint <1.5s\n- **Interaction Responsiveness**: First Input Delay <100ms\n- **Visual Stability**: Cumulative Layout Shift <0.1\n- **Error Rates**: <1% of user sessions encounter UI errors\n- **Accessibility Usage**: Positive feedback from assistive technology users\n\n### Development Metrics\n- **Code Reusability**: >80% of components designed for reuse\n- **Documentation Coverage**: 100% of public component APIs documented\n- **Review Efficiency**: Average 1-2 review cycles per component\n- **Delivery Predictability**: 90% of estimates within 20% accuracy\n- **Collaboration Effectiveness**: Positive feedback from backend developers and designers\n\nRemember: Your role is to create exceptional user interfaces that are accessible, performant, and maintainable while collaborating effectively with the broader development team and adhering to Atlas quality standards.\n\n## File: 05_TEMPLATES/BUG_REPORT_TEMPLATE.md\n## Bug Report\n\n### 1. Describe the Bug\n\nA clear and concise description of what the bug is.\n\n### 2. Steps to Reproduce\n\nSteps to reproduce the behavior:\n1. Go to '...'\n2. Click on '....'\n3. Scroll down to '....'\n4. See error\n\n### 3. Expected Behavior\n\nA clear and concise description of what you expected to happen.\n\n### 4. Actual Behavior\n\nA clear and concise description of what actually happened.\n\n### 5. Evidence\n\nPlease provide screenshots, GIFs, or video recordings of the bug. This is mandatory.\n\n[Insert evidence here]\n\n### 6. Environment\n\nPlease complete the following information:\n- **Device**: [e.g., iPhone 14, Pixel 6, Desktop]\n- **OS**: [e.g., iOS 16.1, Android 13, macOS 13.0]\n- **Browser** (if applicable): [e.g., Chrome 108, Safari 16.1]\n- **App Version**: [e.g., 1.0.2]\n\n### 7. Additional Context\n\nAdd any other context about the problem here.\n\n\n## Dependency: testing_standards\n# Atlas Velocity Tracking System v2.0\n\n## Overview\n\nThe Atlas Velocity Tracking System provides comprehensive metrics to measure and optimize team performance across multiple dimensions. This system goes beyond simple story point tracking to include quality-adjusted velocity, predictability metrics, and continuous improvement indicators.\n\n## Core Velocity Metrics\n\n### 1. Traditional Velocity Metrics\n\n#### Story Point Velocity\n**Definition**: Story points completed per sprint\n**Calculation**: Sum of story points for all completed stories in a sprint\n**Target**: Maintain consistent velocity \u00b115% sprint-over-sprint\n\n```\nSprint Velocity = \u03a3(Completed Story Points)\nRolling Average Velocity = (Last 6 Sprints Velocity) / 6\n```\n\n#### Feature Delivery Rate\n**Definition**: Number of features delivered per sprint\n**Calculation**: Count of features marked as \"Done\" in sprint\n**Target**: Minimum 2 features per sprint, trending upward\n\n```\nFeature Delivery Rate = Count(Completed Features) / Sprint Duration\n```\n\n#### Cycle Time\n**Definition**: Time from story creation to production deployment\n**Calculation**: Average time across all completed stories\n**Target**: <14 days for standard features, <7 days for small features\n\n```\nCycle Time = Deployment Date - Story Creation Date\nAverage Cycle Time = \u03a3(Individual Cycle Times) / Count(Stories)\n```\n\n### 2. Quality-Adjusted Velocity Metrics\n\n#### Quality-Weighted Velocity\n**Definition**: Story points adjusted for quality score\n**Calculation**: Story points \u00d7 (Quality Score / 100)\n**Target**: Quality-weighted velocity \u2265 85% of raw velocity\n\n```\nQuality-Weighted Velocity = \u03a3(Story Points \u00d7 Quality Score / 100)\nQuality Adjustment Factor = Quality-Weighted Velocity / Raw Velocity\n```\n\n#### Defect-Adjusted Velocity\n**Definition**: Story points reduced by defect rework impact\n**Calculation**: Original velocity minus defect remediation effort\n**Target**: Defect impact <10% of total velocity\n\n```\nDefect Impact = \u03a3(Defect Fix Story Points)\nDefect-Adjusted Velocity = Sprint Velocity - Defect Impact\nDefect Rate = Defect Impact / Sprint Velocity\n```\n\n#### First-Time-Right Velocity\n**Definition**: Story points that required no rework or defect fixes\n**Calculation**: Velocity from stories with zero post-completion issues\n**Target**: >90% of delivered story points should be first-time-right\n\n```\nFirst-Time-Right Velocity = \u03a3(Zero-Rework Story Points)\nFirst-Time-Right Rate = First-Time-Right Velocity / Total Velocity\n```\n\n### 3. Predictability Metrics\n\n#### Velocity Variance\n**Definition**: Standard deviation of sprint velocities\n**Calculation**: Statistical variance across recent sprints\n**Target**: Coefficient of variation <20%\n\n```\nVelocity Variance = \u03c3(Sprint Velocities)\nCoefficient of Variation = (Velocity Variance / Mean Velocity) \u00d7 100\n```\n\n#### Commitment Reliability\n**Definition**: Percentage of sprint commitments successfully delivered\n**Calculation**: Completed story points / Committed story points\n**Target**: >85% commitment reliability\n\n```\nCommitment Reliability = (Completed Points / Committed Points) \u00d7 100\nSprint Success Rate = Sprints with >85% Completion / Total Sprints\n```\n\n#### Forecast Accuracy\n**Definition**: Accuracy of velocity-based delivery predictions\n**Calculation**: Predicted vs. actual delivery dates\n**Target**: <10% variance in delivery predictions\n\n```\nForecast Error = |Predicted Date - Actual Date| / Predicted Duration\nForecast Accuracy = (1 - Average Forecast Error) \u00d7 100\n```\n\n### 4. Flow Metrics\n\n#### Work in Progress (WIP)\n**Definition**: Number of stories actively being worked\n**Calculation**: Count of stories in \"In Progress\" states\n**Target**: WIP limit based on team size (typically 1.5 \u00d7 team size)\n\n```\nCurrent WIP = Count(Stories in Progress)\nWIP Utilization = Current WIP / WIP Limit\n```\n\n#### Throughput\n**Definition**: Number of stories completed per time period\n**Calculation**: Stories completed / time period\n**Target**: Consistent throughput aligned with capacity\n\n```\nWeekly Throughput = Stories Completed / Week\nMonthly Throughput = Stories Completed / Month\n```\n\n#### Flow Efficiency\n**Definition**: Percentage of cycle time spent on value-adding work\n**Calculation**: Active work time / total cycle time\n**Target**: >25% flow efficiency\n\n```\nFlow Efficiency = (Active Work Time / Total Cycle Time) \u00d7 100\nWait Time = Total Cycle Time - Active Work Time\n```\n\n## Advanced Velocity Analytics\n\n### 1. Velocity Decomposition Analysis\n\n#### By Story Type\nTrack velocity contribution by story type:\n- **New Features**: 60-70% of velocity\n- **Bug Fixes**: <15% of velocity\n- **Technical Debt**: 10-20% of velocity\n- **Infrastructure**: 5-15% of velocity\n\n#### By Team Member\nIndividual contribution analysis:\n- Velocity per developer\n- Specialization impact\n- Cross-training opportunities\n- Capacity utilization\n\n#### By Epic/Component\nSystem-level velocity tracking:\n- Component delivery rates\n- Epic completion trends\n- Architecture impact on velocity\n\n### 2. Velocity Trend Analysis\n\n#### Seasonal Patterns\n- Holiday impact analysis\n- Training period effects\n- Onboarding ramp-up curves\n- Release preparation impacts\n\n#### Capacity Changes\n- Team size impact\n- New team member integration\n- Knowledge transfer effects\n- Tool and process changes\n\n#### External Dependencies\n- Third-party integration delays\n- Infrastructure bottlenecks\n- Cross-team dependency impacts\n- Customer feedback incorporation\n\n## Velocity Improvement Strategies\n\n### 1. Bottleneck Identification\n\n#### Process Bottlenecks\n- Code review delays\n- Testing resource constraints\n- Deployment pipeline issues\n- Requirements clarification delays\n\n#### Technical Bottlenecks\n- Complex legacy code areas\n- Performance optimization needs\n- Testing environment limitations\n- Tool performance issues\n\n#### Team Bottlenecks\n- Skill gaps in specific areas\n- Communication inefficiencies\n- Decision-making delays\n- Knowledge silos\n\n### 2. Velocity Optimization Techniques\n\n#### Sprint Planning Optimization\n- Better story sizing consistency\n- Improved capacity planning\n- Dependency identification\n- Risk assessment integration\n\n#### Work Breakdown Improvement\n- Smaller, more predictable stories\n- Better acceptance criteria\n- Technical spike identification\n- Cross-cutting concern planning\n\n#### Flow Optimization\n- WIP limit enforcement\n- Batch size reduction\n- Context switching minimization\n- Parallel work stream design\n\n## Velocity Reporting and Dashboards\n\n### 1. Sprint-Level Reports\n\n#### Sprint Velocity Report\n```\nSprint 24 Velocity Summary\n========================\nRaw Velocity: 42 points\nQuality-Adjusted: 38 points (90%)\nCommitment: 40 points\nReliability: 95%\n\nStory Breakdown:\n- Features: 28 points (67%)\n- Bugs: 6 points (14%)\n- Tech Debt: 8 points (19%)\n\nQuality Metrics:\n- Average Quality Score: 85/100\n- First-Time-Right: 36 points (86%)\n- Defect Impact: 2 points (5%)\n```\n\n#### Trend Analysis\n```\n6-Sprint Rolling Metrics\n=======================\nAverage Velocity: 39 \u00b1 4 points\nVelocity Trend: +5% (improving)\nCommitment Reliability: 88%\nQuality Trend: +12% (improving)\n\nBottleneck Analysis:\n1. Code Review: 2.1 days avg\n2. Testing: 1.8 days avg\n3. Requirements: 1.2 days avg\n```\n\n### 2. Release-Level Reports\n\n#### Release Velocity Summary\n```\nRelease 2.1 Summary\n==================\nDuration: 6 sprints\nTotal Velocity: 234 points\nFeatures Delivered: 18\nAverage Quality Score: 87/100\n\nKey Achievements:\n- 12% velocity improvement\n- 25% reduction in cycle time\n- 95% commitment reliability\n- Zero critical production defects\n```\n\n### 3. Velocity Dashboard Components\n\n#### Real-Time Metrics\n- Current sprint progress\n- Daily velocity burn-down\n- WIP limits and utilization\n- Blocked story count\n\n#### Trend Visualizations\n- Velocity trend charts\n- Quality score trends\n- Cycle time trends\n- Predictability metrics\n\n#### Comparative Analytics\n- Team-to-team velocity comparison\n- Project-to-project analysis\n- Historical performance comparison\n- Industry benchmark comparisons\n\n## Velocity Data Collection\n\n### 1. Automated Data Sources\n\n#### Project Management Tools\n- Story point tracking\n- Sprint completion data\n- Cycle time measurements\n- Work item state changes\n\n#### Development Tools\n- Code commit frequency\n- Pull request metrics\n- Build and deployment data\n- Code review timings\n\n#### Quality Systems\n- Test coverage data\n- Defect tracking\n- Quality score calculations\n- User feedback metrics\n\n### 2. Manual Data Collection\n\n#### Sprint Retrospectives\n- Team satisfaction scores\n- Process improvement ideas\n- Bottleneck identification\n- Capacity planning insights\n\n#### Stakeholder Feedback\n- Business value delivery\n- Feature adoption rates\n- Customer satisfaction\n- Market response metrics\n\n## Velocity Forecasting\n\n### 1. Predictive Models\n\n#### Simple Velocity Forecasting\n```python\n# Rolling average prediction\ndef predict_velocity(historical_velocities, periods=3):\n    return sum(historical_velocities[-periods:]) / periods\n\n# Trend-based prediction\ndef predict_with_trend(velocities):\n    trend = calculate_trend(velocities)\n    latest = velocities[-1]\n    return latest + trend\n```\n\n#### Monte Carlo Simulation\n```python\n# Probabilistic velocity forecasting\ndef monte_carlo_forecast(velocities, simulations=1000):\n    # Generate probability distribution\n    mean_velocity = np.mean(velocities)\n    std_velocity = np.std(velocities)\n\n    # Run simulations\n    forecasts = np.random.normal(mean_velocity, std_velocity, simulations)\n\n    return {\n        '50th_percentile': np.percentile(forecasts, 50),\n        '80th_percentile': np.percentile(forecasts, 80),\n        '90th_percentile': np.percentile(forecasts, 90)\n    }\n```\n\n### 2. Release Planning\n\n#### Feature-Based Forecasting\n- Epic-level story point estimation\n- Dependency-adjusted timelines\n- Risk-buffered delivery dates\n- Scope flexibility planning\n\n#### Capacity-Based Planning\n- Team availability forecasting\n- Holiday and training impact\n- Skill development time allocation\n- External dependency coordination\n\n## Velocity Improvement Process\n\n### 1. Weekly Velocity Reviews\n\n#### Review Agenda\n1. Current sprint velocity progress\n2. Bottleneck identification and resolution\n3. Quality impact assessment\n4. Process improvement opportunities\n5. Next sprint capacity planning\n\n#### Action Items\n- Immediate bottleneck removal\n- Process adjustments\n- Tool improvements\n- Skill development needs\n\n### 2. Monthly Velocity Retrospectives\n\n#### Deep Analysis\n- Velocity trend root cause analysis\n- Quality vs. velocity trade-off review\n- Team capacity optimization opportunities\n- Long-term improvement planning\n\n#### Strategic Planning\n- Velocity targets for next quarter\n- Process enhancement roadmap\n- Tool and infrastructure investments\n- Team development plans\n\n## Success Criteria\n\nThe velocity tracking system is successful when:\n\n1. **Predictability Improves**: Forecast accuracy >90%, commitment reliability >85%\n2. **Quality Maintains**: Quality-adjusted velocity \u226585% of raw velocity\n3. **Continuous Improvement**: 5% velocity improvement per quarter\n4. **Sustainable Pace**: Low velocity variance (<20% CV), team satisfaction >4/5\n5. **Business Value**: Feature delivery rate increases, customer satisfaction improves\n\n## Integration with Atlas Framework\n\n### Script Integration\n```bash\n# Calculate current sprint velocity\npython3 velocity_tracker.py current --sprint S2023-24\n\n# Generate velocity report\npython3 velocity_tracker.py report --period 6months --format detailed\n\n# Forecast future velocity\npython3 velocity_tracker.py forecast --method monte_carlo --confidence 80\n```\n\n### Quality Score Integration\n```bash\n# Calculate quality-adjusted velocity\npython3 velocity_tracker.py quality_adjusted --sprint S2023-24\n\n# Track velocity vs quality trends\npython3 velocity_tracker.py trends --include quality --period 1year\n```\n\nThis comprehensive velocity tracking system provides the data and insights needed to continuously improve team performance while maintaining high quality standards.\n\n\n## \u2705 Verification Checklist\n**UI Development Checklist**\n_Frontend implementation quality checks_\n\n### Required Checks:\n- [ ] Implementation matches design specifications\n- [ ] Responsive design works on all screen sizes\n- [ ] Accessibility standards met (WCAG 2.1 AA)\n- [ ] Tested on Chrome, Firefox, Safari, Edge\n- [ ] Existing components reused where possible\n- [ ] State management follows project patterns\n- [ ] Error states handled gracefully\n- [ ] Loading states implemented\n- [ ] Component unit tests written\n\n### Optional Checks:\n- [ ] Core Web Vitals targets met\n\n_Complete 9 required checks before proceeding_", "metadata": {"task": "ui_development", "feature": null, "timestamp": "2025-09-20T11:16:37.902782", "files_included": [{"path": "03_AGENTS/ui_developer_prompt.md", "size": 12214, "priority": 1}, {"path": "05_TEMPLATES/BUG_REPORT_TEMPLATE.md", "size": 862, "priority": 3}], "files_excluded": [{"path": "01_CORE/UI_STANDARDS.md", "reason": "file_not_found"}], "dependencies_resolved": [{"name": "testing_standards", "files": ["04_METRICS/02_VELOCITY_TRACKING.md"]}], "total_tokens": 6452, "cache_key": "ba2896b957d3da82a410c989126148d7", "checklist_included": true, "total_size": 25808}}