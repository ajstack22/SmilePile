{"context": "\n## File: 07_AUTOMATION/doc_aggregator.py\n#!/usr/bin/env python3\n\"\"\"\nAtlas Documentation Aggregator\nEnsures documentation is created for every component and kept up-to-date\n\"\"\"\n\nimport json\nimport os\nfrom pathlib import Path\nfrom datetime import datetime\nfrom typing import Dict, List, Optional\n\nclass DocumentationAggregator:\n    \"\"\"\n    Manages component documentation and ensures completeness\n    \"\"\"\n\n    def __init__(self):\n        self.atlas_dir = Path(__file__).parent.parent\n        self.doc_dir = self.atlas_dir / 'component_docs'\n        self.doc_dir.mkdir(exist_ok=True)\n        self.interface_dir = self.atlas_dir / 'interfaces'\n        self.interface_dir.mkdir(exist_ok=True)\n        self.iteration_dir = self.atlas_dir / 'iterations'\n        self.iteration_dir.mkdir(exist_ok=True)\n\n    def create_component_doc(\n        self,\n        component_name: str,\n        description: str,\n        api: Dict = None,\n        dependencies: List[str] = None,\n        author: str = None\n    ) -> Dict:\n        \"\"\"\n        Create or update documentation for a component\n\n        Args:\n            component_name: Name of the component\n            description: What the component does\n            api: API/interface specification\n            dependencies: Other components this depends on\n            author: Agent or person creating the doc\n\n        Returns:\n            Result of documentation creation\n        \"\"\"\n        doc_path = self.doc_dir / f'{component_name}.md'\n        interface_path = self.interface_dir / f'{component_name}.json'\n\n        # Create markdown documentation\n        doc_content = self._generate_component_doc(\n            component_name,\n            description,\n            api,\n            dependencies,\n            author\n        )\n\n        with open(doc_path, 'w') as f:\n            f.write(doc_content)\n\n        # Save interface specification\n        if api:\n            with open(interface_path, 'w') as f:\n                json.dump(api, f, indent=2)\n\n        return {\n            'action': 'component_documented',\n            'component': component_name,\n            'doc_path': str(doc_path),\n            'interface_path': str(interface_path) if api else None,\n            'timestamp': datetime.now().isoformat()\n        }\n\n    def _generate_component_doc(\n        self,\n        name: str,\n        description: str,\n        api: Dict,\n        dependencies: List[str],\n        author: str\n    ) -> str:\n        \"\"\"Generate markdown documentation for component\"\"\"\n        doc = f\"\"\"# Component: {name}\n\n**Created**: {datetime.now().strftime('%Y-%m-%d')}\n**Author**: {author or 'Unknown'}\n\n## Description\n\n{description}\n\n## Dependencies\n\n\"\"\"\n        if dependencies:\n            for dep in dependencies:\n                doc += f\"- {dep}\\n\"\n        else:\n            doc += \"No external dependencies\\n\"\n\n        if api:\n            doc += \"\"\"\n## API\n\n### Methods\n\"\"\"\n            for method in api.get('methods', []):\n                doc += f\"\"\"\n#### `{method.get('name', 'unknown')}`\n\n{method.get('description', '')}\n\n**Parameters:**\n\"\"\"\n                for param in method.get('parameters', []):\n                    doc += f\"- `{param['name']}` ({param.get('type', 'any')}): {param.get('description', '')}\\n\"\n\n                doc += f\"\"\"\n**Returns:** {method.get('returns', 'void')}\n\n**Example:**\n```{method.get('language', 'javascript')}\n{method.get('example', '// No example provided')}\n```\n\"\"\"\n\n        doc += \"\"\"\n## Integration Points\n\nThis component integrates with the system through:\n\n\"\"\"\n        if api and api.get('integration_points'):\n            for point in api['integration_points']:\n                doc += f\"- {point}\\n\"\n        else:\n            doc += \"- Standard module import/export\\n\"\n\n        doc += \"\"\"\n## Testing\n\n### Test Coverage\n- Target: 80%\n- Current: TBD\n\n### Test Files\n\"\"\"\n        if api and api.get('test_files'):\n            for test_file in api['test_files']:\n                doc += f\"- {test_file}\\n\"\n        else:\n            doc += \"- Tests to be added\\n\"\n\n        doc += \"\"\"\n## Known Issues\n\nNone reported.\n\n## Future Improvements\n\n- Performance optimization\n- Additional error handling\n- Extended API surface\n\"\"\"\n\n        return doc\n\n    def create_iteration_doc(\n        self,\n        iteration: int,\n        feature_name: str,\n        what_was_added: str,\n        how_it_works: str,\n        tests_added: List[str] = None,\n        known_limitations: List[str] = None\n    ) -> Dict:\n        \"\"\"\n        Document an iteration\n\n        Args:\n            iteration: Iteration number\n            feature_name: Name of the feature added\n            what_was_added: Description of changes\n            how_it_works: Technical explanation\n            tests_added: List of tests created\n            known_limitations: Current limitations\n\n        Returns:\n            Result of documentation creation\n        \"\"\"\n        doc_path = self.iteration_dir / f'iteration_{iteration:03d}.md'\n\n        doc_content = f\"\"\"# Iteration {iteration}: {feature_name}\n\n**Date**: {datetime.now().strftime('%Y-%m-%d')}\n\n## What Was Added\n\n{what_was_added}\n\n## How It Works\n\n{how_it_works}\n\n## Tests Added\n\n\"\"\"\n        if tests_added:\n            for test in tests_added:\n                doc_content += f\"- {test}\\n\"\n        else:\n            doc_content += \"- No tests added (NEEDS ATTENTION)\\n\"\n\n        doc_content += \"\"\"\n## API Changes\n\nAny new or modified APIs in this iteration:\n\n```\n// Document API changes here\n```\n\n## Dependencies Added\n\n- None\n\n## Known Limitations\n\n\"\"\"\n        if known_limitations:\n            for limitation in known_limitations:\n                doc_content += f\"- {limitation}\\n\"\n        else:\n            doc_content += \"- None identified\\n\"\n\n        doc_content += \"\"\"\n## Next Steps\n\n- Continue to next iteration\n- Address any limitations\n- Increase test coverage\n\"\"\"\n\n        with open(doc_path, 'w') as f:\n            f.write(doc_content)\n\n        return {\n            'action': 'iteration_documented',\n            'iteration': iteration,\n            'feature': feature_name,\n            'doc_path': str(doc_path),\n            'timestamp': datetime.now().isoformat()\n        }\n\n    def aggregate_dependencies(self, component: str) -> Dict:\n        \"\"\"\n        Aggregate all documentation for a component's dependencies\n\n        Args:\n            component: Component name\n\n        Returns:\n            Aggregated documentation\n        \"\"\"\n        # Read component's doc to find dependencies\n        doc_path = self.doc_dir / f'{component}.md'\n        interface_path = self.interface_dir / f'{component}.json'\n\n        aggregated = {\n            'component': component,\n            'documentation': None,\n            'dependencies': {}\n        }\n\n        # Read main component doc\n        if doc_path.exists():\n            with open(doc_path) as f:\n                aggregated['documentation'] = f.read()\n\n        # Read interface if exists\n        if interface_path.exists():\n            with open(interface_path) as f:\n                interface = json.load(f)\n                deps = interface.get('dependencies', [])\n\n                # Read each dependency's documentation\n                for dep in deps:\n                    dep_doc_path = self.doc_dir / f'{dep}.md'\n                    if dep_doc_path.exists():\n                        with open(dep_doc_path) as f:\n                            aggregated['dependencies'][dep] = {\n                                'documentation': f.read()\n                            }\n\n                    dep_interface_path = self.interface_dir / f'{dep}.json'\n                    if dep_interface_path.exists():\n                        with open(dep_interface_path) as f:\n                            aggregated['dependencies'][dep]['interface'] = json.load(f)\n\n        return aggregated\n\n    def check_documentation_completeness(self) -> Dict:\n        \"\"\"\n        Check if all components have documentation\n\n        Returns:\n            Report on documentation completeness\n        \"\"\"\n        # Find all source files\n        source_extensions = ['.py', '.js', '.ts', '.java', '.kt', '.swift', '.go', '.rs']\n        source_files = []\n\n        for ext in source_extensions:\n            source_files.extend(self.atlas_dir.parent.rglob(f'*{ext}'))\n\n        # Extract component names (simplified - just use file names)\n        components = set()\n        for file in source_files:\n            if not any(skip in str(file) for skip in ['node_modules', '.git', 'build', 'dist']):\n                components.add(file.stem)\n\n        # Check which have documentation\n        documented = set()\n        for doc_file in self.doc_dir.glob('*.md'):\n            documented.add(doc_file.stem)\n\n        missing = components - documented\n        coverage = len(documented) / len(components) * 100 if components else 0\n\n        return {\n            'total_components': len(components),\n            'documented': len(documented),\n            'missing': len(missing),\n            'coverage_percentage': round(coverage, 2),\n            'missing_components': sorted(list(missing))[:20],  # First 20\n            'documented_components': sorted(list(documented))\n        }\n\n    def generate_architecture_doc(self) -> Dict:\n        \"\"\"\n        Generate overall architecture documentation from components\n\n        Returns:\n            Result of architecture doc generation\n        \"\"\"\n        arch_doc = \"\"\"# System Architecture\n\n**Generated**: \"\"\" + datetime.now().strftime('%Y-%m-%d') + \"\"\"\n\n## Overview\n\nThis document describes the overall architecture of the system based on documented components.\n\n## Components\n\n\"\"\"\n        # List all documented components\n        for doc_file in sorted(self.doc_dir.glob('*.md')):\n            component = doc_file.stem\n            arch_doc += f\"### {component}\\n\\n\"\n\n            # Read first few lines of description\n            with open(doc_file) as f:\n                lines = f.readlines()\n                for line in lines:\n                    if line.startswith('## Description'):\n                        # Read until next section\n                        idx = lines.index(line)\n                        for desc_line in lines[idx+2:idx+5]:\n                            if not desc_line.startswith('#'):\n                                arch_doc += desc_line\n                        break\n\n        arch_doc += \"\"\"\n## Component Relationships\n\n```mermaid\ngraph TD\n\"\"\"\n        # Generate component relationship diagram\n        relationships = self._analyze_component_relationships()\n        for rel in relationships:\n            arch_doc += f\"    {rel['from']} --> {rel['to']}\\n\"\n\n        arch_doc += \"\"\"```\n\n## Data Flow\n\n1. User input enters through UI components\n2. Business logic processes in service layer\n3. Data persists through repository layer\n4. Results return to UI\n\n## Key Design Decisions\n\n- Modular architecture for maintainability\n- Clear separation of concerns\n- Test-driven development approach\n- Iterative enhancement model\n\n## Testing Strategy\n\n- Unit tests for each component\n- Integration tests for workflows\n- End-to-end tests for critical paths\n- Performance tests for bottlenecks\n\"\"\"\n\n        arch_path = self.atlas_dir / 'ARCHITECTURE.md'\n        with open(arch_path, 'w') as f:\n            f.write(arch_doc)\n\n        return {\n            'action': 'architecture_generated',\n            'path': str(arch_path),\n            'components_included': len(list(self.doc_dir.glob('*.md'))),\n            'timestamp': datetime.now().isoformat()\n        }\n\n    def _analyze_component_relationships(self) -> List[Dict]:\n        \"\"\"Analyze relationships between components\"\"\"\n        relationships = []\n\n        for interface_file in self.interface_dir.glob('*.json'):\n            with open(interface_file) as f:\n                interface = json.load(f)\n                component = interface_file.stem\n\n                for dep in interface.get('dependencies', []):\n                    relationships.append({\n                        'from': component,\n                        'to': dep\n                    })\n\n        return relationships\n\n    def create_api_documentation(self) -> Dict:\n        \"\"\"\n        Generate API documentation from all interfaces\n\n        Returns:\n            Result of API doc generation\n        \"\"\"\n        api_doc = \"\"\"# API Documentation\n\n**Generated**: \"\"\" + datetime.now().strftime('%Y-%m-%d') + \"\"\"\n\n## Overview\n\nComplete API reference for all system components.\n\n\"\"\"\n\n        for interface_file in sorted(self.interface_dir.glob('*.json')):\n            with open(interface_file) as f:\n                interface = json.load(f)\n                component = interface_file.stem\n\n                api_doc += f\"## {component}\\n\\n\"\n\n                for method in interface.get('methods', []):\n                    api_doc += f\"### `{method.get('name', 'unknown')}`\\n\\n\"\n                    api_doc += f\"{method.get('description', '')}\\n\\n\"\n                    api_doc += \"**Signature:**\\n```\\n\"\n                    api_doc += f\"{method.get('signature', 'No signature provided')}\\n\"\n                    api_doc += \"```\\n\\n\"\n\n        api_path = self.atlas_dir / 'API.md'\n        with open(api_path, 'w') as f:\n            f.write(api_doc)\n\n        return {\n            'action': 'api_documentation_generated',\n            'path': str(api_path),\n            'components': len(list(self.interface_dir.glob('*.json'))),\n            'timestamp': datetime.now().isoformat()\n        }\n\ndef main():\n    \"\"\"CLI interface for documentation aggregator\"\"\"\n    import sys\n\n    aggregator = DocumentationAggregator()\n    args = sys.argv[1:]\n\n    if not args:\n        print(json.dumps({\n            'error': 'No command provided',\n            'usage': {\n                'component': 'doc_aggregator.py component [name] [description] --api api.json --deps dep1,dep2',\n                'iteration': 'doc_aggregator.py iteration [num] [feature] [what] [how]',\n                'check': 'doc_aggregator.py check',\n                'aggregate': 'doc_aggregator.py aggregate [component]',\n                'architecture': 'doc_aggregator.py architecture',\n                'api': 'doc_aggregator.py api'\n            }\n        }, indent=2))\n        return\n\n    command = args[0]\n\n    if command == 'component' and len(args) >= 3:\n        name = args[1]\n        description = args[2]\n\n        api = None\n        dependencies = None\n\n        # Parse optional args\n        if '--api' in args:\n            idx = args.index('--api')\n            if idx + 1 < len(args):\n                api_file = args[idx + 1]\n                if Path(api_file).exists():\n                    with open(api_file) as f:\n                        api = json.load(f)\n\n        if '--deps' in args:\n            idx = args.index('--deps')\n            if idx + 1 < len(args):\n                dependencies = args[idx + 1].split(',')\n\n        result = aggregator.create_component_doc(name, description, api, dependencies)\n        print(json.dumps(result, indent=2))\n\n    elif command == 'iteration' and len(args) >= 5:\n        iteration = int(args[1])\n        feature = args[2]\n        what = args[3]\n        how = args[4]\n\n        tests = None\n        limitations = None\n\n        if '--tests' in args:\n            idx = args.index('--tests')\n            if idx + 1 < len(args):\n                tests = args[idx + 1].split(',')\n\n        if '--limitations' in args:\n            idx = args.index('--limitations')\n            if idx + 1 < len(args):\n                limitations = args[idx + 1].split(',')\n\n        result = aggregator.create_iteration_doc(\n            iteration, feature, what, how, tests, limitations\n        )\n        print(json.dumps(result, indent=2))\n\n    elif command == 'check':\n        result = aggregator.check_documentation_completeness()\n        print(json.dumps(result, indent=2))\n\n    elif command == 'aggregate' and len(args) >= 2:\n        component = args[1]\n        result = aggregator.aggregate_dependencies(component)\n        print(json.dumps(result, indent=2, default=str))\n\n    elif command == 'architecture':\n        result = aggregator.generate_architecture_doc()\n        print(json.dumps(result, indent=2))\n\n    elif command == 'api':\n        result = aggregator.create_api_documentation()\n        print(json.dumps(result, indent=2))\n\n    else:\n        print(json.dumps({\n            'error': f'Unknown command: {command}'\n        }, indent=2))\n\nif __name__ == '__main__':\n    main()\n\n## File: 05_TEMPLATES/README.md\n# Templates\n\nAll templates (was 05_TEMPLATES & 06_TEMPLATES)\n\n\n## Dependency: documentation_standards\n# Atlas Framework\n\nThe unified development workflow framework. No versions, no confusion - just the definitive way to build great software.\n\n## Quick Start\n\n1. **Initialize a workflow**: `python atlas.py workflow start F001`\n2. **Submit for review**: `python atlas.py review submit F001`\n3. **Check status**: `python atlas.py workflow status`\n\n## Structure\n\n- `workflows/` - All workflow documentation\n- `automation/` - All Python scripts and tools\n- `templates/` - All templates and checklists\n- `metrics/` - Metrics and dashboards\n- `agents/` - Agent specifications\n- `standards/` - Standards and agreements\n- `roles/` - Role definitions\n- `integrations/` - External integrations\n\n## The Atlas Way\n\nAtlas provides **one clear path** for each task:\n\n- **Workflow**: Follow `workflows/ATLAS_WORKFLOW.md`\n- **Review**: Use `workflows/REVIEW_PROCESS.md`\n- **Validation**: Run `python atlas.py validate`\n- **Metrics**: Check `python atlas.py metrics`\n\nNo \"enhanced\" versions, no alternatives - just the right way to do things.\n\n## Migration from Previous Versions\n\nIf you're migrating from an older Atlas version, run:\n```bash\npython migrate_to_atlas_2_1.py --backup\n```\n\nThis will consolidate everything into the unified structure.\n\n", "metadata": {"task": "documentation", "feature": null, "timestamp": "2025-09-19T20:52:12.991165", "files_included": [{"path": "07_AUTOMATION/doc_aggregator.py", "size": 16379, "priority": 1}, {"path": "05_TEMPLATES/README.md", "size": 61, "priority": 2}], "files_excluded": [], "dependencies_resolved": [{"name": "documentation_standards", "files": ["09_DOCUMENTATION/README.md"]}], "total_tokens": 4447, "cache_key": "55876228853abf632dec9346a4f372ec", "total_size": 17788}}