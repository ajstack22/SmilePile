#!/bin/bash
# Test Failure Tracker - Automatically detect and respond to test failures
# Part of SmilePile Tiered Testing System

set -euo pipefail

SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
BASELINE_FILE="${PROJECT_ROOT}/.test-failure-baseline.json"
BACKLOG_DIR="${PROJECT_ROOT}/backlog/tech-debt"

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# Function to parse test results and extract failures
parse_test_results() {
    local tier="$1"
    local test_output_file="$2"
    local failures=()

    # Extract failed test names from Gradle output
    while IFS= read -r line; do
        if [[ "$line" =~ ^(.+)\ \>\ (.+)\ FAILED$ ]]; then
            local test_class="${BASH_REMATCH[1]}"
            local test_method="${BASH_REMATCH[2]}"
            failures+=("${test_class}:${test_method}")
        fi
    done < "$test_output_file"

    # Return failures as JSON array
    printf '%s\n' "${failures[@]}" | jq -R . | jq -s .
}

# Function to load baseline failures
load_baseline() {
    if [[ -f "$BASELINE_FILE" ]]; then
        cat "$BASELINE_FILE"
    else
        echo '{"tier1": [], "tier2": [], "tier3": []}'
    fi
}

# Function to save baseline failures
save_baseline() {
    local tier="$1"
    local failures="$2"

    local baseline=$(load_baseline)
    baseline=$(echo "$baseline" | jq --arg tier "$tier" --argjson failures "$failures" '.[$tier] = $failures')
    echo "$baseline" > "$BASELINE_FILE"
}

# Function to detect NEW failures (not in baseline)
detect_new_failures() {
    local tier="$1"
    local current_failures="$2"

    local baseline=$(load_baseline)
    local baseline_failures=$(echo "$baseline" | jq -r --arg tier "$tier" '.[$tier] // []')

    # Find failures in current that are not in baseline
    local new_failures=$(comm -13 \
        <(echo "$baseline_failures" | jq -r '.[]' | sort) \
        <(echo "$current_failures" | jq -r '.[]' | sort))

    echo "$new_failures"
}

# Function to create tech debt story for Tier 3 failures
create_tech_debt_story() {
    local failures="$1"
    local story_id="TECH-DEBT-$(date +%Y%m%d-%H%M%S)"
    local story_file="${BACKLOG_DIR}/${story_id}-tier3-test-failures.md"

    mkdir -p "$BACKLOG_DIR"

    cat > "$story_file" <<EOF
# ${story_id}: Fix Tier 3 Test Failures

**Created:** $(date +"%Y-%m-%d %H:%M:%S")
**Type:** Tech Debt
**Priority:** Medium
**Tier:** 3 (UI/Integration)

## Description

New Tier 3 test failures detected during deployment. These tests are flaky and don't block deployment, but should be fixed to improve test reliability.

## Failed Tests

$(echo "$failures" | while IFS= read -r failure; do
    echo "- \`$failure\`"
done)

## Root Cause

Tier 3 tests typically fail due to:
- Async timing issues with coroutines
- UI test flakiness in test environment
- Integration test environment setup issues

## Recommended Solution

1. **Investigate each failure:**
   - Run tests individually to isolate issues
   - Check if failures are consistent or intermittent

2. **Fix approach:**
   - **For coroutine timing issues:** Refactor ViewModel to inject dispatcher
   - **For UI flakiness:** Convert to integration tests or improve test environment
   - **For environment issues:** Add proper setup/teardown

3. **Move to appropriate tier:**
   - If test becomes stable after fix, consider moving to Tier 2

## Acceptance Criteria

- [ ] All listed tests investigated
- [ ] Root cause identified for each failure
- [ ] Fixes implemented or tests moved/removed
- [ ] Tier 3 test pass rate improves

## Atlas Workflow

Use Atlas Standard workflow for implementation:
\`\`\`bash
# Research failures
cd ${PROJECT_ROOT}
./gradlew app:testTier3UI --info

# Follow Atlas 9-phase workflow to fix
\`\`\`

## Related Documentation

- [Test Tiers](../atlas/docs/TEST_TIERS.md)
- [Testing Strategy](../atlas/docs/TESTING_STRATEGY.md)

---

*Auto-generated by test-failure-tracker.sh*
EOF

    echo "$story_file"
}

# Function to trigger Atlas workflow for Tier 1/2 failures
trigger_atlas_workflow() {
    local tier="$1"
    local failures="$2"

    echo ""
    echo -e "${RED}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━${NC}"
    echo -e "${RED}CRITICAL: ${tier} Test Failures Detected${NC}"
    echo -e "${RED}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━${NC}"
    echo ""
    echo -e "${RED}New ${tier} test failures detected:${NC}"
    echo "$failures" | while IFS= read -r failure; do
        echo -e "  ${RED}❌ $failure${NC}"
    done
    echo ""
    echo -e "${YELLOW}ACTION REQUIRED: Atlas Workflow Triggered${NC}"
    echo ""
    echo "The following steps will be executed:"
    echo "  1. Create bug story in backlog"
    echo "  2. Trigger Atlas development workflow"
    echo "  3. Block deployment until resolved"
    echo ""

    # Create bug story
    local story_id="BUG-$(date +%Y%m%d-%H%M%S)"
    local story_file="${PROJECT_ROOT}/backlog/bugs/${story_id}-${tier,,}-test-failures.md"

    mkdir -p "${PROJECT_ROOT}/backlog/bugs"

    cat > "$story_file" <<EOF
# ${story_id}: CRITICAL - ${tier} Test Failures

**Created:** $(date +"%Y-%m-%d %H:%M:%S")
**Type:** Bug
**Priority:** CRITICAL
**Tier:** ${tier}
**Status:** BLOCKING DEPLOYMENT

## Description

**CRITICAL:** New ${tier} test failures detected during deployment. These tests verify critical functionality and MUST be fixed before deployment can proceed.

## Failed Tests

$(echo "$failures" | while IFS= read -r failure; do
    echo "- \`$failure\`"
done)

## Impact

**Deployment Blocked:** These failures indicate potential issues with:
$(if [[ "$tier" == "Tier 1" ]]; then
    echo "- Security (encryption, authentication)"
    echo "- Data integrity (storage, repositories)"
    echo "- Critical safety features"
else
    echo "- Business logic (ViewModels, services)"
    echo "- Core application features"
    echo "- Data operations"
fi)

## Immediate Action Required

**Use Atlas Emergency workflow to resolve:**

\`\`\`bash
# 1. Investigate failures
cd ${PROJECT_ROOT}/android
./gradlew app:test${tier/Tier /}Critical --info

# 2. Run Atlas workflow (auto-triggered)
# Follow prompts to fix issues

# 3. Verify fix
./gradlew app:test${tier/Tier /}Critical

# 4. Resume deployment
./deploy/deploy_qual.sh
\`\`\`

## Atlas Workflow Steps

1. **Phase 1 (Research):** Identify root cause of each failure
2. **Phase 2 (Story):** Update this story with findings
3. **Phase 3 (Planning):** Create fix plan
4. **Phase 4 (Security Review):** Validate no security regressions
5. **Phase 5 (Implementation):** Fix failures
6. **Phase 6 (Testing):** Verify all tests pass
7. **Phase 7 (Validation):** Run full test suite
8. **Phase 8 (Documentation):** Update test documentation
9. **Phase 9 (Deployment):** Resume deployment

## Related Documentation

- [Test Tiers](../atlas/docs/TEST_TIERS.md)
- [Testing Strategy](../atlas/docs/TESTING_STRATEGY.md)
- [Atlas Workflow](../atlas/docs/AGENT_WORKFLOW.md)

---

*Auto-generated by test-failure-tracker.sh - REQUIRES IMMEDIATE ATTENTION*
EOF

    echo -e "${BLUE}Bug story created: $story_file${NC}"
    echo ""
    echo -e "${YELLOW}Press ENTER to continue with Atlas workflow, or Ctrl+C to abort...${NC}"
    read -r

    # TODO: Trigger Atlas workflow agent
    echo -e "${BLUE}Would trigger Atlas workflow here...${NC}"
    echo "For now, please manually follow the steps in: $story_file"
    echo ""

    return 1  # Return error to block deployment
}

# Main function
main() {
    local tier="${1:-}"
    local test_output_file="${2:-}"

    if [[ -z "$tier" ]] || [[ -z "$test_output_file" ]]; then
        echo "Usage: $0 <tier> <test_output_file>"
        echo ""
        echo "Example:"
        echo "  $0 tier1 /tmp/tier1-test-output.txt"
        exit 1
    fi

    if [[ ! -f "$test_output_file" ]]; then
        echo -e "${RED}Error: Test output file not found: $test_output_file${NC}"
        exit 1
    fi

    echo -e "${BLUE}Analyzing ${tier} test results...${NC}"

    # Parse current test failures
    local current_failures=$(parse_test_results "$tier" "$test_output_file")
    local failure_count=$(echo "$current_failures" | jq '. | length')

    if [[ "$failure_count" -eq 0 ]]; then
        echo -e "${GREEN}✅ No ${tier} failures detected${NC}"
        return 0
    fi

    echo -e "${YELLOW}Found $failure_count ${tier} failure(s)${NC}"

    # Detect NEW failures (not in baseline)
    local new_failures=$(detect_new_failures "$tier" "$current_failures")
    local new_count=$(echo "$new_failures" | wc -l | tr -d ' ')

    if [[ "$new_count" -eq 0 ]] || [[ -z "$new_failures" ]]; then
        echo -e "${BLUE}ℹ️  All failures are known (in baseline)${NC}"
        echo -e "${BLUE}No action needed${NC}"
        return 0
    fi

    echo -e "${YELLOW}⚠️  Detected $new_count NEW failure(s):${NC}"
    echo "$new_failures" | while IFS= read -r failure; do
        echo -e "  ${YELLOW}• $failure${NC}"
    done
    echo ""

    # Handle based on tier
    case "$tier" in
        tier1|Tier1)
            trigger_atlas_workflow "Tier 1" "$new_failures"
            ;;
        tier2|Tier2)
            trigger_atlas_workflow "Tier 2" "$new_failures"
            ;;
        tier3|Tier3)
            echo -e "${BLUE}Creating tech debt story for Tier 3 failures...${NC}"
            local story_file=$(create_tech_debt_story "$new_failures")
            echo -e "${GREEN}✅ Tech debt story created: $story_file${NC}"
            echo ""
            echo -e "${BLUE}ℹ️  Tier 3 failures are non-blocking. Deployment can continue.${NC}"
            echo -e "${BLUE}Please review and schedule fixes: $story_file${NC}"

            # Update baseline to include these failures
            save_baseline "$tier" "$current_failures"
            return 0
            ;;
        *)
            echo -e "${RED}Unknown tier: $tier${NC}"
            exit 1
            ;;
    esac
}

main "$@"
